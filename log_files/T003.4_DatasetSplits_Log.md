# T003.4 - Train/Validation/Test Splits Implementation Log

**Subtask**: 3.4 - Create train/validation/test splits (80/10/10)
**Date**: 2025-12-04
**Status**: Completed

---

## Objective

Implement dataset splitting functionality to divide formatted datasets into train, validation, and test sets with configurable ratios (default 80/10/10).

---

## Files Modified/Created

### Modified

- `scripts/prepare_datasets.py` - Added split utility functions and CLI options

### Created

- `tests/test_task003_4_dataset_splits.py` - 23 tests

---

## Implementation Details

### New Functions Added

| Function | Purpose |
|----------|---------|
| `create_splits()` | Split indices into train/val/test sets |
| `copy_split_files()` | Copy files by index to destination |
| `split_dataset()` | Main function to split formatted datasets |
| `_split_tatr_dataset()` | Split COCO format (TATR) datasets |
| `_split_layoutlm_dataset()` | Split LayoutLM format datasets |

### New CLI Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `--split` | flag | False | Enable dataset splitting |
| `--train-ratio` | float | 0.8 | Training set fraction |
| `--val-ratio` | float | 0.1 | Validation set fraction |
| `--test-ratio` | float | 0.1 | Test set fraction |

---

## Split Algorithm

```python
def create_splits(indices, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):
    # 1. Shuffle indices with seed for reproducibility
    random.seed(seed)
    shuffled = indices.copy()
    random.shuffle(shuffled)

    # 2. Calculate split points
    n = len(shuffled)
    train_end = int(n * train_ratio)
    val_end = train_end + int(n * val_ratio)

    # 3. Return splits
    return {
        'train': shuffled[:train_end],
        'val': shuffled[train_end:val_end],
        'test': shuffled[val_end:]
    }
```

---

## Output Structure

### TATR Format
```
data/formatted/tatr/
├── train/
│   ├── annotations.json  # COCO annotations for train set
│   └── images/
│       └── *.png
├── val/
│   ├── annotations.json
│   └── images/
└── test/
    ├── annotations.json
    └── images/
```

### LayoutLM Format
```
data/formatted/layoutlm/
├── train/
│   ├── samples.json      # Train samples
│   ├── labels.json       # Label mapping (copied to all splits)
│   └── images/
├── val/
│   ├── samples.json
│   ├── labels.json
│   └── images/
└── test/
    ├── samples.json
    ├── labels.json
    └── images/
```

---

## Key Features

### 1. Reproducibility
- Uses seed for deterministic splits
- Same seed always produces same splits

### 2. Disjoint Splits
- No sample appears in multiple splits
- All samples assigned to exactly one split

### 3. Flexible Ratios
- Default: 80% train, 10% val, 10% test
- Customizable via CLI options

### 4. Format-Aware Splitting
- TATR: Splits COCO annotations and images
- LayoutLM: Splits samples.json and copies labels.json to each split

---

## Usage

```bash
# Format and split in one command
python scripts/prepare_datasets.py --format both --split

# Custom split ratios
python scripts/prepare_datasets.py --format tatr --split \
    --train-ratio 0.7 --val-ratio 0.2 --test-ratio 0.1

# Split with specific seed
python scripts/prepare_datasets.py --split --seed 123
```

---

## COCO Annotation Splitting

For TATR datasets, annotations are split along with images:

```python
# Build image_id to annotations mapping
img_to_anns = {}
for ann in annotations:
    img_id = ann['image_id']
    if img_id not in img_to_anns:
        img_to_anns[img_id] = []
    img_to_anns[img_id].append(ann)

# Get annotations for split images
split_annotations = []
for img in split_images:
    split_annotations.extend(img_to_anns.get(img['id'], []))
```

---

## Error Handling

- Missing files are skipped gracefully
- Empty datasets return empty splits
- Invalid format types return error dict

---

## Test Summary

| Category | Tests |
|----------|-------|
| Module Functions Exist | 3 |
| create_splits() | 9 |
| split_dataset() | 2 |
| TATR Splitting | 2 |
| LayoutLM Splitting | 2 |
| copy_split_files() | 2 |
| CLI Integration | 3 |
| **Total** | **23** |

---

## Performance

- Efficient O(n) splitting algorithm
- File copying uses shutil.copy2 for metadata preservation
- No full dataset loading required (streaming approach)

---

## Next Steps

- **Subtask 3.5**: Validate dataset format compatibility with Hugging Face
