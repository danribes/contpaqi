# T007.1 LayoutLM Module Structure - Learning Guide

## Overview

This guide explains the LayoutLMv3 model integration for token classification on invoice images. LayoutLM is a multimodal model that combines text, layout (position), and image information.

## What is LayoutLM?

**LayoutLMv3** is a pre-trained multimodal model from Microsoft designed for document understanding tasks:
- **Text**: The actual words on the document
- **Layout**: Position information (bounding boxes)
- **Vision**: The document image

It's particularly effective for forms, invoices, receipts, and other structured documents.

## Token Classification

Token classification assigns a label to each token (word) in the document:

```
Input:  ["RFC:", "ABC123456789", "Total:", "$1,234.56"]
Output: ["O",    "B-RFC_EMISOR", "O",      "B-TOTAL"]
```

## BIO Tagging Scheme

BIO (Begin-Inside-Outside) is a standard scheme for sequence labeling:

| Tag | Meaning | Example |
|-----|---------|---------|
| O | Outside | Words not part of any field |
| B-X | Beginning | First token of field X |
| I-X | Inside | Continuation tokens of field X |

### Example
```
Tokens: ["Empresa", "ABC", "S.A.", "de", "C.V."]
Labels: ["O",       "B-ITEM_DESC", "I-ITEM_DESC", "I-ITEM_DESC", "I-ITEM_DESC"]
```

The company name "ABC S.A. de C.V." spans 4 tokens, so:
- "ABC" gets `B-ITEM_DESC` (beginning)
- Rest get `I-ITEM_DESC` (inside/continuation)

## Invoice Fields (10 Entity Types)

| Field | Description | Example |
|-------|-------------|---------|
| RFC_EMISOR | Issuer tax ID | ABC123456789 |
| RFC_RECEPTOR | Receiver tax ID | XYZ987654321 |
| DATE | Invoice date | 15/01/2024 |
| SUBTOTAL | Before tax | $1,000.00 |
| IVA | Tax (16%) | $160.00 |
| TOTAL | Final amount | $1,160.00 |
| ITEM_DESC | Line item name | Widget Pro |
| ITEM_QTY | Quantity | 5 |
| ITEM_PRICE | Unit price | $200.00 |
| ITEM_AMOUNT | Line total | $1,000.00 |

## ExtractedField Dataclass

Represents a complete extracted field after grouping BIO tokens:

```python
@dataclass
class ExtractedField:
    label: str       # Field type (e.g., 'RFC_EMISOR')
    value: str       # Concatenated text
    confidence: float # Average confidence
    bbox: tuple      # Merged bounding box
```

### Merging Logic
When multiple tokens form one field:
- **value**: Concatenate with spaces
- **confidence**: Average of all tokens
- **bbox**: Union (min x1/y1, max x2/y2)

## Model Architecture

```
Image + Words + Boxes
        ↓
   LayoutLMv3Processor (tokenization + encoding)
        ↓
   LayoutLMv3ForTokenClassification (transformer)
        ↓
   21 logits per token (one per label)
        ↓
   Argmax → Label prediction
```

## Key Methods

### predict()
```python
def predict(self, image, words, boxes) -> List[Dict]:
    """
    Args:
        image: PIL Image
        words: ["word1", "word2", ...]
        boxes: [(x1,y1,x2,y2), ...]

    Returns:
        [{'word': 'ABC', 'label': 'B-RFC', 'confidence': 0.95, 'bbox': (...)}]
    """
```

### extract_fields()
```python
def extract_fields(self, predictions) -> Dict[str, ExtractedField]:
    """
    Groups BIO-tagged tokens into complete fields.

    Returns:
        {'RFC_EMISOR': ExtractedField(...), 'TOTAL': ExtractedField(...)}
    """
```

## Box Normalization

LayoutLM expects boxes normalized to 0-1000 scale:

```python
normalized_box = [
    int(box[0] * 1000 / width),
    int(box[1] * 1000 / height),
    int(box[2] * 1000 / width),
    int(box[3] * 1000 / height)
]
```

## Integration with Pipeline

```
1. PDF → Image (Task 5: OCR)
2. Image → Table/Row Bboxes (Task 6: TATR)
3. Image + Words → Field Labels (Task 7: LayoutLM) <-- This task
4. All Results → Structured Invoice (Task 8: Inference)
```

## Why 21 Labels?

1 "O" label + 10 entity types × 2 (B- and I-) = 21

```python
LABELS = [
    'O',                              # 1
    'B-RFC_EMISOR', 'I-RFC_EMISOR',   # 2-3
    'B-RFC_RECEPTOR', 'I-RFC_RECEPTOR', # 4-5
    # ... (10 entity types × 2 = 20)
]  # Total: 21
```

## Summary

Subtask 7.1 creates the module structure:
- `ExtractedField` dataclass for structured output
- `LayoutLMModel` class with 21 BIO labels
- Method stubs for predict() and extract_fields()
- Conditional imports for torch/transformers
- Validation for confidence and bbox

Next subtasks will implement:
- 7.2: Model loading
- 7.3: Token classification inference
- 7.4: Field extraction logic
