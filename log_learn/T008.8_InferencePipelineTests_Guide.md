# T008.8 Inference Pipeline Tests - Learning Guide

## Overview
This guide explains the testing strategy for the inference pipeline, including unit tests with mocks and integration tests with fixtures.

## Test Organization

```
mcp-container/
├── tests/
│   ├── __init__.py
│   ├── test_inference.py    # Pipeline tests
│   └── fixtures/
│       └── sample_invoice.png  # (future)
```

## Two-Tier Testing Strategy

### Tier 1: Unit Tests with Mocks
Test individual components in isolation:

```python
def test_predict_extracts_rfc_emisor(self):
    engine = InvoiceInferenceEngine(load_models=False)

    # Mock pipeline steps
    engine._run_ocr = Mock(return_value=(['RFC'], [(0,0,30,10)], [0.9]))
    engine._detect_table_structure = Mock(return_value={'table': None, 'rows': []})
    engine._extract_fields = Mock(return_value={'RFC_EMISOR': mock_rfc})
    engine._assign_words_to_rows = Mock(return_value=[])

    result = engine.predict(Mock())
    assert result.rfc_emisor == 'XAXX010101000'
```

**Advantages:**
- Fast execution
- No ML model dependencies
- Isolated testing
- Always runnable

### Tier 2: Integration Tests with Fixtures
Test the complete pipeline with real data:

```python
@pytest.mark.skipif(not HAS_FIXTURES, reason="Fixtures not available")
class TestIntegrationWithFixtures:

    @pytest.fixture
    def engine(self):
        return InvoiceInferenceEngine(load_models=True)

    @pytest.fixture
    def sample_invoice(self):
        return Image.open(SAMPLE_INVOICE_PATH)

    def test_predict_returns_result(self, engine, sample_invoice):
        result = engine.predict(sample_invoice)
        assert isinstance(result, InvoiceResult)
```

**Advantages:**
- Tests real behavior
- Validates ML models
- End-to-end verification

## Skip Decorators Pattern

```python
# Check if fixtures are available
FIXTURES_DIR = Path(__file__).parent / 'fixtures'
SAMPLE_INVOICE_PATH = FIXTURES_DIR / 'sample_invoice.png'
HAS_FIXTURES = SAMPLE_INVOICE_PATH.exists()

@pytest.mark.skipif(not HAS_FIXTURES, reason="Sample invoice fixtures not available")
class TestIntegrationWithFixtures:
    ...
```

This pattern allows:
- CI to run without fixtures
- Local development with fixtures
- Clear skip reasons in test output

## Test Categories Explained

### Import Tests
Verify module structure:
```python
def test_can_import_inference_module(self):
    from inference import InvoiceInferenceEngine, InvoiceResult
    assert InvoiceInferenceEngine is not None
```

### Initialization Tests
Verify engine setup:
```python
def test_engine_has_all_pipeline_methods(self):
    engine = InvoiceInferenceEngine(load_models=False)
    required_methods = ['_run_ocr', '_detect_table_structure', ...]
    for method in required_methods:
        assert hasattr(engine, method)
```

### Extraction Tests
Verify field extraction:
```python
def test_predict_extracts_amounts(self):
    # Test subtotal, iva, total extraction
    assert result.subtotal == 1000.0
    assert result.iva == 160.0
    assert result.total == 1160.0
```

### Currency Parsing Tests
Verify amount parsing formats:
```python
def test_parses_amount_with_currency_symbol(self):
    mock_total.value = '$1,500.00'
    assert result.total == 1500.00

def test_parses_amount_with_thousand_separators(self):
    mock_total.value = '1,234,567.89'
    assert result.total == 1234567.89
```

### Confidence Tests
Verify scoring logic:
```python
def test_high_confidence_with_all_required_fields(self):
    fields = {'RFC_EMISOR': ..., 'RFC_RECEPTOR': ..., 'TOTAL': ...}
    assert result.confidence > 0.8
```

## Adding Fixtures

To enable integration tests:

1. Create a sample invoice image:
   ```
   mcp-container/tests/fixtures/sample_invoice.png
   ```

2. The integration tests will automatically run:
   ```bash
   pytest mcp-container/tests/test_inference.py -v
   # Now shows: 23 passed instead of 18 passed, 5 skipped
   ```

## Best Practices

1. **Mock at Boundaries**: Mock pipeline methods, not internal details
2. **Test Real Behavior**: Integration tests verify actual ML output
3. **Clear Skip Reasons**: Explain why tests are skipped
4. **Comprehensive Coverage**: Test all extraction scenarios
5. **Graceful Degradation**: Tests run with or without fixtures

## Key Takeaways

1. **Two-tier strategy**: Mocks for unit tests, fixtures for integration
2. **Skip decorators**: Graceful handling of missing fixtures
3. **Complete coverage**: All pipeline aspects tested
4. **Future-ready**: Integration tests ready for real invoices
