# T008.2 OCR Method Integration - Learning Guide

## Overview
This guide explains how the `_run_ocr()` method integrates the OCREngine into the InvoiceInferenceEngine.

## The Integration Pattern

The inference engine uses **composition** to combine multiple AI components:

```
InvoiceInferenceEngine
├── ocr: OCREngine        ◄─── Used by _run_ocr()
├── tatr: TATRModel       ◄─── Used by _run_tatr()
└── layoutlm: LayoutLMModel ◄─── Used by _run_layoutlm()
```

## Method Design

### Separation of Concerns
Each `_run_*` method handles one component:

```python
def _run_ocr(self, image):
    """Only handles OCR extraction."""
    words = self.ocr.extract_words(image)
    return texts, boxes, confidences

def _run_tatr(self, image):
    """Only handles table detection."""
    ...

def _run_layoutlm(self, image, texts, boxes):
    """Only handles field classification."""
    ...
```

### Data Transformation
The method transforms OCRWord objects into parallel lists:

```python
# Input: List of OCRWord objects
words = [
    OCRWord(text='Hello', bbox=(10,20,50,40), confidence=0.95),
    OCRWord(text='World', bbox=(60,20,100,40), confidence=0.90),
]

# Output: Three parallel lists
texts = ['Hello', 'World']
boxes = [(10,20,50,40), (60,20,100,40)]
confidences = [0.95, 0.90]
```

## Why Parallel Lists?

### Flexibility
Different consumers need different data:
- LayoutLM needs texts + boxes
- Confidence filtering needs confidences + texts
- Visualization needs boxes alone

### Memory Efficiency
Parallel lists avoid duplicating data:

```python
# ❌ Less efficient: passing full objects
layoutlm.predict(image, words)  # Each word carries all data

# ✅ More efficient: passing only needed data
layoutlm.predict(image, texts, boxes)  # Only what's needed
```

## List Comprehension Pattern

```python
texts = [w.text for w in words]
boxes = [w.bbox for w in words]
confidences = [w.confidence for w in words]
```

This is equivalent to but more concise than:

```python
texts = []
boxes = []
confidences = []
for w in words:
    texts.append(w.text)
    boxes.append(w.bbox)
    confidences.append(w.confidence)
```

## Debug Logging

```python
logger.debug("Running OCR...")
# ... do work ...
logger.debug(f"OCR extracted {len(words)} words")
```

Benefits:
- Track progress in complex pipelines
- Debug without print statements
- Configurable verbosity at runtime

## Error Handling Strategy

The method **doesn't validate** `self.ocr`:

```python
def _run_ocr(self, image):
    # No check: if ocr is None, let it fail naturally
    words = self.ocr.extract_words(image)  # AttributeError if None
```

Why?
1. **Fail fast**: Errors surface immediately
2. **Clear stack traces**: Shows exact failure point
3. **No silent failures**: Never returns empty silently

## Testing Without Real OCR

Use mocks to test without Tesseract:

```python
engine = InvoiceInferenceEngine(load_models=False)

# Create mock OCR
mock_ocr = Mock()
mock_ocr.extract_words.return_value = [
    Mock(text='Test', bbox=(0,0,10,10), confidence=0.9)
]
engine.ocr = mock_ocr

# Now test
result = engine._run_ocr(fake_image)
```

## Key Takeaways

1. **Composition**: Engine combines OCR, TATR, LayoutLM
2. **Parallel lists**: Flexible, efficient data format
3. **List comprehensions**: Concise attribute extraction
4. **Debug logging**: Track pipeline progress
5. **Fail fast**: No silent error handling
