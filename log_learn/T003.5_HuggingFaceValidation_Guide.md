# T003.5 - Hugging Face Dataset Validation Guide

**Subtask**: 3.5 - Validate dataset format compatibility with Hugging Face
**Date**: 2025-12-04

---

## What We Built

A validation system that ensures our formatted datasets are compatible with Hugging Face's `datasets` and `transformers` libraries before training models.

---

## Why Validation Matters

### The Problem

Without validation, you might discover format issues only when:
1. Loading the dataset fails during training
2. The model produces garbage predictions
3. Hours of training are wasted

### The Solution

Early validation catches:
- Missing required fields
- Type mismatches
- Value range errors
- Structural inconsistencies

---

## COCO Format for Object Detection (TATR)

### What is COCO Format?

COCO (Common Objects in Context) is a standard format for object detection datasets used by models like DETR, TATR, and Detectron2.

### Structure

```json
{
  "images": [
    {
      "id": 1,
      "file_name": "image.png",
      "width": 800,
      "height": 600
    }
  ],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "bbox": [100, 100, 400, 300]  // [x, y, width, height]
    }
  ],
  "categories": [
    {
      "id": 1,
      "name": "table",
      "supercategory": "document"
    }
  ]
}
```

### Key Points

1. **Image IDs must be unique** - Each image has a distinct ID
2. **Annotations reference images** - `image_id` must exist in images
3. **Bbox format** - [x, y, width, height] not [x1, y1, x2, y2]
4. **Categories are shared** - Same categories for all images

---

## LayoutLM Format for Token Classification

### What is LayoutLM Format?

LayoutLM uses a document understanding format combining text, layout (bboxes), and labels.

### Structure

```json
[
  {
    "tokens": ["Invoice", "Total:", "$100"],
    "bboxes": [[0, 0, 100, 50], [0, 50, 100, 100], [100, 50, 200, 100]],
    "ner_tags": [0, 0, 3],
    "image_path": "invoice.png"
  }
]
```

### Key Points

1. **Parallel arrays** - tokens, bboxes, ner_tags must have same length
2. **Bbox format** - [x1, y1, x2, y2] normalized to 0-1000
3. **NER tags are integers** - Index into label list
4. **Labels stored separately** - labels.json with ["O", "B-TOTAL", ...]

---

## Validation Function Design

### Return Value Pattern

All validation functions return a consistent structure:

```python
{
    'valid': True/False,      # Overall pass/fail
    'errors': [],             # List of error messages
    'warnings': [],           # Non-fatal issues
    # Plus format-specific stats
}
```

### Error vs Warning

| Type | Action | Example |
|------|--------|---------|
| Error | Validation fails | Missing required field |
| Warning | Validation passes | Orphaned annotation |

---

## Implementation Patterns

### 1. Required Fields Check

```python
required_keys = ['tokens', 'bboxes', 'ner_tags', 'image_path']
for key in required_keys:
    if key not in sample:
        errors.append(f"Sample {i}: missing '{key}' field")
```

### 2. Length Consistency

```python
if len(tokens) != len(bboxes):
    errors.append(f"Sample {i}: length mismatch")
```

### 3. Value Range Validation

```python
if tag < 0 or tag >= num_labels:
    errors.append(f"Tag {tag} out of range [0, {num_labels-1}]")
```

### 4. Type Checking

```python
if not isinstance(bbox, list) or len(bbox) != 4:
    errors.append(f"Bbox must be list of 4 values")
```

---

## Using Hugging Face Libraries

### Loading with datasets

```python
from datasets import Dataset, load_dataset

# From list
dataset = Dataset.from_list(samples)

# From JSON files
dataset = load_dataset(
    'json',
    data_files={
        'train': 'train/samples.json',
        'validation': 'val/samples.json',
        'test': 'test/samples.json'
    }
)
```

### Using with Transformers

```python
from transformers import LayoutLMv3Processor

processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base")

# Encode sample
encoding = processor(
    images=image,
    text=tokens,
    boxes=bboxes,
    word_labels=ner_tags,
    return_tensors="pt"
)
```

---

## Common Errors and Fixes

### 1. "Missing 'tokens' field"
```python
# ‚ùå Wrong
sample = {'words': ['a', 'b'], ...}

# ‚úì Correct
sample = {'tokens': ['a', 'b'], ...}
```

### 2. "Length mismatch"
```python
# ‚ùå Wrong
{'tokens': ['a', 'b'], 'bboxes': [[0,0,10,10]]}  # 2 tokens, 1 bbox

# ‚úì Correct
{'tokens': ['a', 'b'], 'bboxes': [[0,0,10,10], [10,0,20,10]]}
```

### 3. "NER tag out of range"
```python
# ‚ùå Wrong - labels has 5 items (0-4), tag is 5
labels = ['O', 'B-A', 'I-A', 'B-B', 'I-B']
sample = {'ner_tags': [0, 5, 0]}  # 5 is invalid

# ‚úì Correct
sample = {'ner_tags': [0, 3, 0]}  # 3 = B-B, valid
```

---

## CLI Usage

```bash
# Format and validate in one step
python scripts/prepare_datasets.py \
    --input-dir data/synthetic \
    --output-dir data/formatted \
    --format both \
    --split \
    --validate

# Validate existing dataset
python scripts/prepare_datasets.py \
    --input-dir data/formatted \
    --validate
```

---

## Best Practices

| Practice | Why |
|----------|-----|
| Validate before training | Catch errors early |
| Check all splits | Train/val/test might differ |
| Log statistics | Understand your data |
| Test with small batch first | Fast iteration |

---

## Task 3 Complete!

With this subtask, the entire data preparation pipeline is complete:

```
Raw PDFs + Labels
       ‚Üì
[3.1] prepare_datasets.py CLI
       ‚Üì
[3.2] COCO Format (TATR)  +  [3.3] LayoutLM Format (BIO)
       ‚Üì                           ‚Üì
[3.4] Train/Val/Test Splits
       ‚Üì
[3.5] Hugging Face Validation
       ‚Üì
Ready for Model Training! üöÄ
```
