# T003.4 - Dataset Splitting Guide

**Subtask**: 3.4 - Create train/validation/test splits (80/10/10)
**Date**: 2025-12-04

---

## What We Built

A dataset splitting utility that divides formatted invoice datasets into train, validation, and test sets for machine learning model training.

---

## Why Dataset Splitting Matters

### The Problem
Machine learning models need three separate datasets:

1. **Training Set** (~80%): Model learns from this data
2. **Validation Set** (~10%): Used to tune hyperparameters and prevent overfitting
3. **Test Set** (~10%): Final evaluation, never seen during training

### Why Not Just Use All Data for Training?

| Scenario | Result |
|----------|--------|
| Train on all data | Model memorizes data, fails on new invoices |
| Train + validate on same data | Overfit hyperparameters, poor generalization |
| Proper splits | Model generalizes well to unseen invoices |

---

## Key Concepts

### 1. Reproducibility with Seeds

```python
import random
random.seed(42)  # Same seed = same "random" shuffle

# Now every time we run this code, we get identical splits
# This is crucial for:
# - Reproducing experiments
# - Comparing model versions
# - Debugging issues
```

### 2. Disjoint Splits

Splits must be **mutually exclusive** - no sample can appear in multiple sets:

```
Dataset: [A, B, C, D, E, F, G, H, I, J]

❌ BAD:
  Train: [A, B, C, D, E, F, G, H]  (contains H)
  Val:   [H, I]                    (also contains H!)
  Test:  [I, J]

✓ GOOD:
  Train: [A, B, C, D, E, F, G, H]
  Val:   [I]
  Test:  [J]
```

### 3. Stratified vs Random Splitting

**Random Splitting** (what we implemented):
- Simpler, works well for large datasets
- Each sample has equal probability of being in any split

**Stratified Splitting** (future enhancement):
- Maintains class distribution in each split
- Important when some invoice types are rare

---

## How the Code Works

### Step 1: Create Index List

```python
# Given 100 invoices, create indices
indices = list(range(100))  # [0, 1, 2, ..., 99]
```

### Step 2: Shuffle with Seed

```python
import random
random.seed(42)
shuffled = indices.copy()
random.shuffle(shuffled)
# [23, 87, 45, 12, ...]  # Deterministic "random" order
```

### Step 3: Calculate Split Points

```python
n = 100  # total samples
train_ratio = 0.8
val_ratio = 0.1

train_end = int(100 * 0.8)  # 80
val_end = 80 + int(100 * 0.1)  # 90
```

### Step 4: Slice the Array

```python
train = shuffled[:80]   # First 80 samples
val = shuffled[80:90]   # Next 10 samples
test = shuffled[90:]    # Remaining 10 samples
```

---

## Format-Specific Considerations

### COCO Format (TATR)

The COCO format has linked data:
- Images have IDs
- Annotations reference image IDs

When splitting, we must keep annotations with their images:

```python
# Build mapping: image_id -> [annotations]
img_to_anns = {}
for ann in annotations:
    img_id = ann['image_id']
    img_to_anns.setdefault(img_id, []).append(ann)

# When copying images, include their annotations
for img in split_images:
    split_anns.extend(img_to_anns.get(img['id'], []))
```

### LayoutLM Format

LayoutLM has:
- samples.json (list of samples)
- labels.json (label definitions)

Labels are constant across all splits (same label set), so we copy labels.json to each split directory.

---

## Common Pitfalls

### 1. Data Leakage

```python
# ❌ WRONG: Preprocessing before splitting
normalized_data = normalize(all_data)
train, val, test = split(normalized_data)
# Problem: Normalization used test data statistics!

# ✓ CORRECT: Split first, then preprocess
train, val, test = split(all_data)
train = normalize(train, fit=True)  # Compute stats from train only
val = normalize(val, fit=False)     # Use train stats
test = normalize(test, fit=False)   # Use train stats
```

### 2. Non-Deterministic Splits

```python
# ❌ WRONG: No seed
random.shuffle(data)  # Different every time!

# ✓ CORRECT: Use seed
random.seed(42)
random.shuffle(data)  # Same shuffle every time
```

### 3. Forgetting to Copy Associated Files

```python
# ❌ WRONG: Only copy samples
copy_samples(train_samples, train_dir)

# ✓ CORRECT: Copy all associated files
copy_samples(train_samples, train_dir)
copy_images(train_images, train_dir)
copy_labels(labels, train_dir)  # Same labels for all splits
```

---

## Testing Strategy

### Unit Tests

```python
def test_splits_are_disjoint():
    """No sample should appear in multiple splits."""
    splits = create_splits(range(100))

    train_set = set(splits['train'])
    val_set = set(splits['val'])
    test_set = set(splits['test'])

    # Intersection should be empty
    assert len(train_set & val_set) == 0
    assert len(train_set & test_set) == 0
    assert len(val_set & test_set) == 0
```

### Integration Tests

```python
def test_splits_coco_annotations():
    """COCO annotations should be split correctly."""
    # Create 20 sample images with annotations
    # Split with 80/10/10
    # Verify train has 16 images
```

---

## CLI Usage Examples

```bash
# Basic: Format and split
python prepare_datasets.py --format both --split

# Custom ratios for more validation data
python prepare_datasets.py --split \
    --train-ratio 0.7 \
    --val-ratio 0.2 \
    --test-ratio 0.1

# Reproducible splits with specific seed
python prepare_datasets.py --split --seed 123

# Full example
python prepare_datasets.py \
    --input-dir data/synthetic \
    --output-dir data/formatted \
    --format both \
    --split \
    --seed 42
```

---

## Best Practices Summary

| Practice | Why |
|----------|-----|
| Always use a seed | Reproducibility |
| 80/10/10 is a good default | Balances training data with evaluation |
| Keep test set untouched | Only use for final evaluation |
| Verify splits are disjoint | Prevent data leakage |
| Copy all associated files | Maintain data integrity |

---

## Next Steps

After splitting, the datasets are ready for:

1. **Hugging Face Datasets** - Load with `datasets.load_dataset()`
2. **Model Training** - Train TATR and LayoutLM models
3. **Evaluation** - Use val set during training, test set for final metrics
