# T007.2 LayoutLMv3 Model Loading - Learning Guide

## Overview
This guide explains how to load LayoutLMv3 for token classification tasks.

## LayoutLMv3 Model Types

| Class | Purpose |
|-------|---------|
| `LayoutLMv3Model` | Base model (embeddings only) |
| `LayoutLMv3ForTokenClassification` | Token classification head |
| `LayoutLMv3ForSequenceClassification` | Document classification |
| `LayoutLMv3ForQuestionAnswering` | Extractive QA |

We use **ForTokenClassification** for labeling each word.

## Loading with num_labels

```python
model = LayoutLMv3ForTokenClassification.from_pretrained(
    "microsoft/layoutlmv3-base",
    num_labels=21  # Our BIO label count
)
```

### Why num_labels?

The base model doesn't have a classification head. Setting `num_labels`:
1. Adds a linear classification layer
2. Initializes random weights for that layer
3. Model needs fine-tuning on your data

```
LayoutLMv3 Base → Token Embeddings (768-dim)
                         ↓
Classification Head → 21 logits per token
```

## LayoutLMv3Processor

Handles both image and text preprocessing:

```python
processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base")

# Usage
encoding = processor(
    image,           # PIL Image
    words,           # List of strings
    boxes=boxes,     # List of [x1,y1,x2,y2] normalized to 0-1000
    return_tensors="pt"
)
```

## Label Mappings

For inference, we need to convert between labels and IDs:

```python
# During init
self.label2id = {label: idx for idx, label in enumerate(self.LABELS)}
self.id2label = {idx: label for idx, label in enumerate(self.LABELS)}

# During inference
prediction_id = 5
label = self.id2label[prediction_id]  # e.g., "B-DATE"
```

## Eval Mode

```python
model.eval()
```

Essential for inference:
- Disables dropout
- Freezes batch normalization
- Deterministic output

## Complete Loading Pattern

```python
class LayoutLMModel:
    def __init__(self, model_name=None, device=None, load_model=True):
        self.model_name = model_name or "microsoft/layoutlmv3-base"
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

        # Label mappings
        self.label2id = {l: i for i, l in enumerate(self.LABELS)}
        self.id2label = {i: l for i, l in enumerate(self.LABELS)}

        self.model = None
        self.processor = None
        self._model_loaded = False

        if load_model:
            self._load_model()

    def _load_model(self):
        self.processor = LayoutLMv3Processor.from_pretrained(self.model_name)
        self.model = LayoutLMv3ForTokenClassification.from_pretrained(
            self.model_name,
            num_labels=len(self.LABELS)
        )
        self.model.to(self.device)
        self.model.eval()
        self._model_loaded = True
```

## Fine-tuning Note

The base model needs fine-tuning for invoice extraction:

```python
# After fine-tuning, save model
model.save_pretrained("./models/layoutlm-invoice")

# Load fine-tuned model
model = LayoutLMv3ForTokenClassification.from_pretrained(
    "./models/layoutlm-invoice"
)
```
