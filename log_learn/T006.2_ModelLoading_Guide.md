# T006.2 Model Loading - Learning Guide

## Overview
This guide explains how to load HuggingFace models for inference.

## HuggingFace Model Loading

### Processor and Model
```python
# Processor: Handles image preprocessing
processor = AutoImageProcessor.from_pretrained("microsoft/table-transformer-detection")

# Model: The neural network
model = AutoModelForObjectDetection.from_pretrained("microsoft/table-transformer-detection")
```

### from_pretrained()

Downloads and caches:
- Model weights
- Configuration
- Tokenizer/processor

First call downloads, subsequent calls use cache.

## Device Selection

```python
if torch.cuda.is_available():
    device = "cuda"  # GPU - fast
else:
    device = "cpu"   # CPU - slower but works everywhere
```

### Moving Model to Device
```python
model.to(device)  # Move model to GPU/CPU
```

## Eval Mode

```python
model.eval()
```

Why?
- Disables dropout (training randomness)
- Disables batch normalization updates
- Consistent inference results

## Lazy Loading Pattern

```python
class TATRModel:
    def __init__(self, load_model=True):
        self._model_loaded = False
        if load_model:
            self._load_model()

    def _ensure_model_loaded(self):
        if not self._model_loaded:
            self._load_model()
```

Benefits:
- `load_model=False` for testing
- Load only when needed
- Configure before loading

## Label Mapping

```python
# Model's config has label mapping
self.ID2LABEL = model.config.id2label
# {0: "table", 1: "table row", ...}
```

## Error Handling

```python
def _load_model(self):
    if not TORCH_AVAILABLE:
        raise RuntimeError("Install PyTorch: pip install torch")
    if not TRANSFORMERS_AVAILABLE:
        raise RuntimeError("Install Transformers: pip install transformers")
```

Fail fast with clear instructions.

## Complete Loading Flow

```
__init__(load_model=True)
    ↓
Check TORCH_AVAILABLE
    ↓
Check TRANSFORMERS_AVAILABLE
    ↓
AutoImageProcessor.from_pretrained()
    ↓
AutoModelForObjectDetection.from_pretrained()
    ↓
model.to(device)
    ↓
model.eval()
    ↓
Update ID2LABEL from config
```
