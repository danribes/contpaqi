# T006.3 Detection Inference - Learning Guide

## Overview
This guide explains how to run object detection inference with Table Transformer.

## Inference Pipeline

```
Image → Preprocess → Model → Post-process → Detections
```

## Step 1: Preprocessing

```python
inputs = processor(images=image, return_tensors="pt")
```

What happens:
- Resize image to model's expected size
- Normalize pixel values
- Convert to PyTorch tensor

### Moving to Device
```python
inputs = {k: v.to(device) for k, v in inputs.items()}
```

## Step 2: Inference

```python
with torch.no_grad():
    outputs = model(**inputs)
```

### Why no_grad()?

```python
# Without no_grad()
outputs = model(**inputs)
# PyTorch tracks gradients (for training)
# Uses more memory, slower

# With no_grad()
with torch.no_grad():
    outputs = model(**inputs)
# No gradient tracking
# Faster, less memory
```

**Always use no_grad() for inference!**

## Step 3: Post-processing

```python
target_sizes = torch.tensor([image.size[::-1]])  # (height, width)

results = processor.post_process_object_detection(
    outputs,
    target_sizes=target_sizes,
    threshold=threshold
)[0]  # First (only) image
```

### Why [::-1]?
- PIL Image.size returns `(width, height)`
- Model expects `(height, width)`
- `[::-1]` reverses the tuple

### Threshold
- Filters detections by confidence
- 0.7 = 70% confidence minimum

## Step 4: Convert to Dataclass

```python
for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    detections.append(TableDetection(
        label=self.ID2LABEL[label.item()],  # int → string
        confidence=score.item(),             # tensor → float
        bbox=tuple(box.tolist())             # tensor → tuple
    ))
```

### .item() and .tolist()
- Tensors aren't JSON serializable
- `.item()` → Python scalar
- `.tolist()` → Python list/tuple

## Complete detect() Method

```python
def detect(self, image, threshold=None):
    self._ensure_model_loaded()
    threshold = threshold or self.threshold

    # Preprocess
    inputs = self.processor(images=image, return_tensors="pt")
    inputs = {k: v.to(self.device) for k, v in inputs.items()}

    # Inference
    with torch.no_grad():
        outputs = self.model(**inputs)

    # Post-process
    target_sizes = torch.tensor([image.size[::-1]])
    results = self.processor.post_process_object_detection(
        outputs, target_sizes=target_sizes, threshold=threshold
    )[0]

    # Convert
    return [TableDetection(...) for ...]
```
